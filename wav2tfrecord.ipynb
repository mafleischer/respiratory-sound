{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport re\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.train import FloatList, Int64List, BytesList, Feature, Features, FeatureList, FeatureLists, SequenceExample\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport soundfile as sf\n\ntry:\n    os.environ['KAGGLE_DATA_PROXY_TOKEN']\nexcept KeyError:\n    dir_out = \"./\"\n    dir_files = \"Respiratory_Sound_Database/Respiratory_Sound_Database/\"\nelse:\n    dir_out = \"/kaggle/working/\"\n    dir_files = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n\ndir_audio = dir_files + \"audio_and_txt_files/\"\nfname_tfrecord = dir_out + \"wavs.tfrecord\"\n\n### Read WAVs and pad ###\n    \ngroup_pat_num = \"([0-9]{3})\"\ngroup_rec_index = \"([0-9][a-z][0-9])\"\ngroup_chest_loc = \"(Tc|Al|Ar|Pl|Pr|Ll|Lr)\"\ngroup_acc_modes = \"(sc|mc)\"\ngroup_equipments = \"(AKGC417L|LittC2SE|Litt3200|Meditron)\"\n\nregex_info = re.compile(\"_\".join([group_pat_num, group_rec_index, group_chest_loc, group_acc_modes, group_equipments]))\n\ntop = os.getcwd()\nos.chdir(dir_audio)\nfnames = glob.glob(\"*.wav\")\n\nl_wav_rec = []\ndict_wav_rec = {}\nmin_len = np.inf\nmax_len = 0\n\n### !!!!!!!!!!!! remove [:3]\n\nfor fname in fnames[:3]:\n    match_info = regex_info.match(fname)\n    pat_num = int(match_info.group(1))\n    rec_index = match_info.group(2)\n    chest_loc = match_info.group(3)\n    acc_mode = match_info.group(4)\n    equipment = match_info.group(5)\n    \n    wav_content = sf.read(fname)[0]\n    l_wav_rec.append([pat_num, rec_index, chest_loc, wav_content])\n    dict_wav_rec[(pat_num, rec_index, chest_loc)] = wav_content\n    \n    if len(wav_content) > max_len:\n        max_len = len(wav_content)\n        # for getting the corresponding annotation below\n        max_patnum = pat_num\n        max_recindex = rec_index\n        max_chestloc = chest_loc\n    \n    if len(wav_content) < min_len:\n        min_len = len(wav_content)\n        # for getting the corresponding annotation below\n        min_patnum = pat_num\n        min_recindex = rec_index\n        min_chestloc = chest_loc\n\nos.chdir(top)\n\n# pad all recordings to same length\nfor i in range(len(l_wav_rec)):\n    if len(l_wav_rec[i][3]) < max_len:\n        padding = [0] * ( max_len - len(l_wav_rec[i][3]) )\n        l_wav_rec[i][3] = np.append(l_wav_rec[i][3], padding)\n\n# pad all recordings to multiple of length of shortest recording\n# for i in range(len(l_wav_rec)):\n#     if len(l_wav_rec[i][3]) % min_len != 0:\n#         padding = [0] * ( min_len - len(l_wav_rec[i][3]) % min_len)\n#         l_wav_rec[i][3] = np.append(l_wav_rec[i][3], padding)\n\nl_wav_rec.sort(key=lambda subl: (subl[0], subl[1], subl[2]))\n\n# wav_cols = [\"Patient number\", \"Recording index\", \"Chest location\", \"WAV\"]\n# df_wav_rec = pd.DataFrame(l_wav_rec, columns=wav_cols)\n\n######\n\n# for wav_rec in l_wav_rec:\n#     wav_transposed = tf.reshape(tf.constant(l_wav_rec[0][3], dtype=tf.float32), shape=[-1, 1])\n\nfeat_patnum = Feature(\n    int64_list = Int64List(value=[l_wav_rec[0][0]])\n)\n\nfeat_recix = Feature(\n    bytes_list = BytesList(value=[bytes(l_wav_rec[0][1], \"ascii\")])\n)\n\nfeat_chestloc = Feature(\n    bytes_list = BytesList(value=[bytes(l_wav_rec[0][2], \"ascii\")])\n)\n\nfeatures_context = Features(\n    feature = {\n        \"patient number\" : feat_patnum,\n        \"recording index\" : feat_recix,\n        \"chest location\" : feat_chestloc\n    }\n)\n\n# wav_transposed = tf.reshape(tf.constant(l_wav_rec[0][3], dtype=tf.float32), shape=[-1, 1])\n\n# fl = []\n\n# for val_ix in range(len(l_wav_rec[0][3])):\n#     feature = Feature(\n#         float_list = FloatList(value=([l_wav_rec[0][3][val_ix]]))\n#     )\n    \n#     fl.append(feature)\n\n# feat_list = FeatureList(feature = fl)\n\n# fls = {}    \n# fls[\"{} {} {}\".format(l_wav_rec[0][0], l_wav_rec[0][1], l_wav_rec[0][2])] = feat_list\n\n# feat_lists = FeatureLists(feature_list = fls)\n\n# se = SequenceExample(\n#     context = features_context,\n#     feature_lists = feat_lists\n# )\n    \n# with tf.io.TFRecordWriter(fname_tfrecord) as f:\n#     f.write(se.SerializeToString())\n\nfeature_description = {\n        \"patient number\" : tf.io.FixedLenFeature([], tf.int64),\n        \"recording index\" : tf.io.FixedLenFeature([], tf.string),\n        \"chest location\" : tf.io.FixedLenFeature([], tf.string)\n    }\n\nfor serialized in tf.data.TFRecordDataset([fname_tfrecord]):\n    parsed = tf.io.parse_sequence_example(serialized, feature_description)\n\nprint(parsed)","execution_count":6,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"Value for attr 'Tcontext_dense' of int16 is not in the list of allowed values: float, int64, string\n\t; NodeDef: {{node ParseSequenceExampleV2}}; Op<name=ParseSequenceExampleV2; signature=serialized:string, debug_name:string, context_sparse_keys:string, context_dense_keys:string, context_ragged_keys:string, feature_list_sparse_keys:string, feature_list_dense_keys:string, feature_list_ragged_keys:string, feature_list_dense_missing_assumed_empty:bool, context_dense_defaults: -> context_sparse_indices:Ncontext_sparse*int64, context_sparse_values:, context_sparse_shapes:Ncontext_sparse*int64, context_dense_values:, context_ragged_values:, context_ragged_row_splits:, feature_list_sparse_indices:Nfeature_list_sparse*int64, feature_list_sparse_values:, feature_list_sparse_shapes:Nfeature_list_sparse*int64, feature_list_dense_values:, feature_list_dense_lengths:Nfeature_list_dense*int64, feature_list_ragged_values:, feature_list_ragged_outer_splits:, feature_list_ragged_inner_splits:; attr=Ncontext_sparse:int,default=0,min=0; attr=Tcontext_dense:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=context_dense_shapes:list(shape),default=[],min=0; attr=Nfeature_list_sparse:int,default=0,min=0; attr=Nfeature_list_dense:int,default=0,min=0; attr=feature_list_dense_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=feature_list_dense_shapes:list(shape),default=[],min=0> [Op:ParseSequenceExampleV2]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-0f64e39f26ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname_tfrecord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sequence_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_sequence_example\u001b[0;34m(serialized, context_features, sequence_features, example_names, name)\u001b[0m\n\u001b[1;32m    561\u001b[0m     outputs = _parse_sequence_example_raw(serialized, example_names,\n\u001b[1;32m    562\u001b[0m                                           \u001b[0mcontext_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                                           name)\n\u001b[0m\u001b[1;32m    564\u001b[0m     \u001b[0mcontext_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_sequence_example_raw\u001b[0;34m(serialized, debug_name, context, feature_list, name)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mcontext_dense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shapes_as_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mfeature_list_dense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    652\u001b[0m     (context_sparse_indices, context_sparse_values, context_sparse_shapes,\n\u001b[1;32m    653\u001b[0m      \u001b[0mcontext_dense_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_ragged_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_ragged_row_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_sequence_example_v2\u001b[0;34m(serialized, debug_name, context_sparse_keys, context_dense_keys, context_ragged_keys, feature_list_sparse_keys, feature_list_dense_keys, feature_list_ragged_keys, feature_list_dense_missing_assumed_empty, context_dense_defaults, Ncontext_sparse, context_sparse_types, context_ragged_value_types, context_ragged_split_types, context_dense_shapes, Nfeature_list_sparse, Nfeature_list_dense, feature_list_dense_types, feature_list_sparse_types, feature_list_ragged_value_types, feature_list_ragged_split_types, feature_list_dense_shapes, name)\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0mfeature_list_ragged_split_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list_ragged_split_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m           \u001b[0mfeature_list_dense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list_dense_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_sequence_example_v2_eager_fallback\u001b[0;34m(serialized, debug_name, context_sparse_keys, context_dense_keys, context_ragged_keys, feature_list_sparse_keys, feature_list_dense_keys, feature_list_ragged_keys, feature_list_dense_missing_assumed_empty, context_dense_defaults, Ncontext_sparse, context_sparse_types, context_ragged_value_types, context_ragged_split_types, context_dense_shapes, Nfeature_list_sparse, Nfeature_list_dense, feature_list_dense_types, feature_list_sparse_types, feature_list_ragged_value_types, feature_list_ragged_split_types, feature_list_dense_shapes, name, ctx)\u001b[0m\n\u001b[1;32m   1628\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_list_ragged_split_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m                              \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_inputs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m                              name=name)\n\u001b[0m\u001b[1;32m   1631\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m     _execute.record_gradient(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'Tcontext_dense' of int16 is not in the list of allowed values: float, int64, string\n\t; NodeDef: {{node ParseSequenceExampleV2}}; Op<name=ParseSequenceExampleV2; signature=serialized:string, debug_name:string, context_sparse_keys:string, context_dense_keys:string, context_ragged_keys:string, feature_list_sparse_keys:string, feature_list_dense_keys:string, feature_list_ragged_keys:string, feature_list_dense_missing_assumed_empty:bool, context_dense_defaults: -> context_sparse_indices:Ncontext_sparse*int64, context_sparse_values:, context_sparse_shapes:Ncontext_sparse*int64, context_dense_values:, context_ragged_values:, context_ragged_row_splits:, feature_list_sparse_indices:Nfeature_list_sparse*int64, feature_list_sparse_values:, feature_list_sparse_shapes:Nfeature_list_sparse*int64, feature_list_dense_values:, feature_list_dense_lengths:Nfeature_list_dense*int64, feature_list_ragged_values:, feature_list_ragged_outer_splits:, feature_list_ragged_inner_splits:; attr=Ncontext_sparse:int,default=0,min=0; attr=Tcontext_dense:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=context_dense_shapes:list(shape),default=[],min=0; attr=Nfeature_list_sparse:int,default=0,min=0; attr=Nfeature_list_dense:int,default=0,min=0; attr=feature_list_dense_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=feature_list_dense_shapes:list(shape),default=[],min=0> [Op:ParseSequenceExampleV2]"]}]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}