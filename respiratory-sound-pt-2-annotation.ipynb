{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Respiratoy sound automatic annotation (1D Conv, without spectrograms, no downsampling)\nAttempt automatic annotation of sound files in the same format as the provided text files.\nUse the sound data directly without creating spectograms"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport copy\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport soundfile as sf\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, precision_recall_curve, plot_precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\ntry:\n    os.environ['KAGGLE_DATA_PROXY_TOKEN']\nexcept KeyError:\n    dir_out = \"./\"\n    dir_files = \"Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    dir_annot_csv = \"./\"\n    fname_demo = dir_path + \"demographic_info.txt\"\nelse:\n    dir_out = \"/kaggle/working/\"\n    dir_files = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    dir_annot_csv = \"/kaggle/input/recording-annotations/\"\n    fname_demo = \"/kaggle/input/respiratory-sound-database/\" + \"demographic_info.txt\"\n    \nfname_diag = dir_files + \"patient_diagnosis.csv\"\nfname_annot = dir_annot_csv + \"rec_annotation.csv\"\ntfrecord_wavs = dir_out + \"wavs.tfrecord\"\ntfrecord_annot = dir_out + \"annot.tfrecord\"\ndir_audio = dir_files + \"audio_and_txt_files/\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"group_pat_num = \"([0-9]{3})\"\ngroup_rec_index = \"([0-9][a-z][0-9])\"\ngroup_chest_loc = \"(Tc|Al|Ar|Pl|Pr|Ll|Lr)\"\ngroup_acc_modes = \"(sc|mc)\"\ngroup_equipments = \"(AKGC417L|LittC2SE|Litt3200|Meditron)\"\n\nregex_info = re.compile(\"_\".join([group_pat_num, group_rec_index, group_chest_loc, group_acc_modes, group_equipments]))\n\ntop = os.getcwd()\nos.chdir(dir_audio)\nfnames = glob.glob(\"*.wav\")\n\nl_wav_rec = []\ndict_wav_rec = {}\nmin_len = np.inf\nmax_len = 0\n\nfor fname in fnames:\n    match_info = regex_info.match(fname)\n    pat_num = int(match_info.group(1))\n    rec_index = match_info.group(2)\n    chest_loc = match_info.group(3)\n    acc_mode = match_info.group(4)\n    equipment = match_info.group(5)\n    \n    wav_content = sf.read(fname)[0]\n    l_wav_rec.append([pat_num, rec_index, chest_loc, wav_content])\n    dict_wav_rec[(pat_num, rec_index, chest_loc)] = wav_content\n    \n    if len(wav_content) > max_len:\n        max_len = len(wav_content)\n        # for getting the corresponding annotation below\n        max_patnum = pat_num\n        max_recindex = rec_index\n        max_chestloc = chest_loc\n    \n    if len(wav_content) < min_len:\n        min_len = len(wav_content)\n        # for getting the corresponding annotation below\n        min_patnum = pat_num\n        min_recindex = rec_index\n        min_chestloc = chest_loc\n\nos.chdir(top)\n\n# pad all recordings to same length\nfor i in range(len(l_wav_rec)):\n    if len(l_wav_rec[i][3]) < max_len:\n        padding = [0] * ( max_len - len(l_wav_rec[i][3]) )\n        l_wav_rec[i][3] = np.append(l_wav_rec[i][3], padding)\n\n# pad all recordings to multiple of length of shortest recording\n# for i in range(len(l_wav_rec)):\n#     if len(l_wav_rec[i][3]) % min_len != 0:\n#         padding = [0] * ( min_len - len(l_wav_rec[i][3]) % min_len)\n#         l_wav_rec[i][3] = np.append(l_wav_rec[i][3], padding)\n\nl_wav_rec.sort(key=lambda subl: (subl[0], subl[1], subl[2]))\nwav_cols = [\"Patient number\", \"Recording index\", \"Chest location\", \"WAV\"]\ndf_wav_rec = pd.DataFrame(l_wav_rec, columns=wav_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get annotation corresponding to smallest wave file\ndf_annot = pd.read_csv(fname_annot).set_index([\"Patient number\", \"Recording index\", \"Chest location\"])\ndf_annot = df_annot.sort_index()\n# df_min_annot = df_annot.loc[min_patnum, min_recindex, min_chestloc]\n# df_max_annot = df_annot.loc[max_patnum, max_recindex, max_chestloc]\n\nmax_len_annot = 0\nmax_ix = None\n\nfor ix in df_annot.index:\n    cur_annot = df_annot.loc[ix, [\"Cycle start\", \"Cycle end\", \"Crackles\", \"Wheezes\"]]\n    # pad additional \"dummy\" rows to maximum length annotation\n    if len(cur_annot) > max_len_annot:\n        max_len_annot = len(cur_annot)\n        df_max_annot = cur_annot\n#         max_ix = ix\n\n# construct CNN target feature maps\ntarget_feature_maps = np.empty((0,max_len_annot,4), dtype=\"float32\")\nfor ix in df_annot.index:\n    cur_annot = df_annot.loc[ix, [\"Cycle start\", \"Cycle end\", \"Crackles\", \"Wheezes\"]].to_numpy()\n    # pad additional \"dummy\" rows to maximum length annotation\n    if len(cur_annot) < max_len_annot:\n        pad_len = max_len_annot - len(cur_annot)\n        # what's the best way of padding?\n        padding = np.array([[-1, -1, 0, 0]] * pad_len)\n        cur_annot = np.vstack((cur_annot, padding))\n    feature_map = cur_annot[np.newaxis, :]\n    target_feature_maps = np.append(target_feature_maps, feature_map, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for val_ix in range(len(l_wav_rec[0][3])):\n#     feature = Feature(\n#         float_list = FloatList(value=([l_wav_rec[0][3][val_ix]]))\n#     )\n    \n#     feats = [feature]\n    \n#     feat_list = FeatureList(feature = feats)\n    \n#     feat_lists_dict[\"{} {} {} {}\".format(l_wav_rec[0][0], l_wav_rec[0][1], l_wav_rec[0][2], val_ix)] = feat_list\n    \n#     sequence_description[\"{} {} {} {}\".format(l_wav_rec[0][0], l_wav_rec[0][1], l_wav_rec[0][2], val_ix)] = tf.io.FixedLenSequenceFeature([1], tf.float32)\n\n# tfr_options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\ntfr_options = tf.io.TFRecordOptions()\nf = tf.io.TFRecordWriter(tfrecord_wavs, tfr_options)\n\nfor rec in l_wav_rec:\n    \n#     feat_patnum = Feature(\n#         int64_list = Int64List(value=[rec[0]])\n#     )\n\n#     feat_recix = Feature(\n#         bytes_list = BytesList(value=[bytes(rec[1], \"ascii\")])\n#     )\n\n#     feat_chestloc = Feature(\n#         bytes_list = BytesList(value=[bytes(rec[2], \"ascii\")])\n#     )\n\n#     features_context = Features(\n#         feature = {\n#             \"patient number\" : feat_patnum,\n#             \"recording index\" : feat_recix,\n#             \"chest location\" : feat_chestloc\n#         }\n#     )\n    \n    \n    \n#     feat_list = [ Feature(\n#             float_list = FloatList(value=(rec[3]))\n#         )\n#     ]\n\n\n#     feat_lists_dict = {}    \n#     feat_lists_dict[\"WAV\"] = FeatureList(feature = feat_list)\n#     feat_lists = FeatureLists(feature_list = feat_lists_dict)\n    \n#     feat_rec_str = Feature(\n#         bytes_list = BytesList(value=[bytes(\"{}_{}_{}\".format(rec[0], rec[1], rec[2]), \"ascii\")])\n#     )\n#     features_context = Features(\n#         feature = {\n#             \"Recording string\" : feat_rec_str\n#         }\n#     )\n\n    \n\n#     se = SequenceExample(\n#         context = features_context,\n#         feature_lists = feat_lists\n#     )\n\n\n#     f.write(se.SerializeToString())\n    \n    \n    reshaped_tensor = tf.reshape(tf.constant(rec[3], dtype=tf.float32), shape=[-1, 1])\n    f.write(tf.io.serialize_tensor(reshaped_tensor).numpy())\n    \n\nf.close()\n\n# free RAM\ndel l_wav_rec\n\n\n\nwith tf.io.TFRecordWriter(tfrecord_annot, tfr_options) as f:\n    f.write(tf.io.serialize_tensor(tf.constant(target_feature_maps, dtype=tf.float32)).numpy())\n\n# del target_feature_maps\n    \n# feature_context = {\n#     \"patient number\" : tf.io.FixedLenFeature([], tf.int64),\n#     \"recording index\" : tf.io.FixedLenFeature([], tf.string),\n#     \"chest location\" : tf.io.FixedLenFeature([], tf.string)\n#     }\n\n# feature_context = {\n#     \"Recording string\" : tf.io.FixedLenFeature([], tf.string)\n# }\n\n\n# sequence_description = {\n#     \"WAV\" : tf.io.FixedLenSequenceFeature([max_len], tf.float32)\n# }\n\n# for serialized in tf.data.TFRecordDataset([fname_tfrecord]).batch(10):\n#     parsed = tf.io.parse_sequence_example(serialized, feature_context, sequence_description)\n    \n# for serialized in tf.data.TFRecordDataset([fname_tfrecord], compression_type=\"GZIP\").batch(10):\n#     for s in serialized:\n#         parsed_tensor = tf.io.parse_tensor(s, tf.float32)\n#         print(parsed_tensor)\n\n\n    \n\n# print(tf.reshape(tf.constant(parsed[1]['WAV'], dtype=tf.float32), shape=[-1, 1]))\n# print(parsed)\n# print(l_wav_rec[2][3])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for serialized in tf.data.TFRecordDataset([tfrecord_annot]).batch(2):\n#     for s in serialized:\n#         parsed_tensor = tf.io.parse_tensor(s, tf.float32)\n#         print(parsed_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def datasetFromTFRecord(fpath=tfrecord_wavs, batch_size=10):\n    \n    tfr_wav = tf.data.TFRecordDataset([tfrecord_wavs])\n    tfr_annot = tf.data.TFRecordDataset([tfrecord_annot])\n#     serialized = tfr_dataset.batch(batch_size)\n    parsed_wavs = tfr_wav.map(lambda ser : tf.io.parse_tensor(ser, tf.float32))\n    parsed_annot = tfr_annot.map(lambda ser : tf.io.parse_tensor(ser, tf.float32)).unbatch()\n#     batch_target = copy.deepcopy(target_feature_maps[:batch_size])\n#     batch_target = copy.deepcopy(target_feature_maps[:3])\n#     target_data = tf.data.Dataset.from_tensors(batch_target)\n#     target_data = tf.expand_dims(tf.constant(batch_target), 0)\n\n    \n#     wavs_batch = tf.constant(list(parsed_wavs.batch(batch_size).prefetch(1).as_numpy_iterator()))\n    \n    zipped = tf.data.Dataset.zip((parsed_wavs, parsed_annot))\n    \n#     data = tf.data.Dataset.from_tensor_slices((parsed_wavs, parsed_annot))\n    \n#     np.delete(target_feature_maps, batch_size)\n    \n#     data = tf.data.Dataset.from_tensor_slices((wavs_batch, target_data))\n    \n#     return parsed_wavs.batch(batch_size).prefetch(1), target_data.batch(batch_size).prefetch(1)\n#     return data.batch(batch_size).prefetch(1)\n    \n    return zipped.batch(batch_size).prefetch(1)\n#     return data.batch(batch_size).prefetch(1)\n\n\n\n\n# for serialized in tf.data.TFRecordDataset([fname_tfrecord], compression_type=\"GZIP\").batch(10):\n# for serialized in tf.data.TFRecordDataset([tfrecord_annot]).batch(2):\n#     for s in serialized:\n#         parsed_tensor = tf.io.parse_tensor(s, tf.float32)\n#         print(parsed_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x1 = np.array([[df_wav_rec.loc[0, \"WAV\"].astype(\"float32\")]])\nx1 = np.array([df_wav_rec.loc[0, \"WAV\"].astype(\"float32\")]).reshape(-1,1)[np.newaxis,:,:]\nconv = keras.layers.Conv1D(filters=4,kernel_size=5, strides=2, padding=\"same\", activation=\"relu\")\n\ncnn_strides = [1,2,4]\nfmap_size = max_len\n\nmodel = keras.models.Sequential(name=\"1DCNN\")\nfor i in range(len(cnn_strides)):\n    if i == 0:\n        layer_name = \"conv_input\"\n    else:\n        layer_name = \"conv_{}\".format(i)\n    model.add(keras.layers.Conv1D(filters = 64 / (2 ** i) , kernel_size= 5 * (2 ** i), strides=cnn_strides[i], padding=\"same\", activation=\"relu\", name=layer_name))\n    fmap_size //= cnn_strides[i]\n\n# calculate this in order to get the last stride number that results in a output feature map of\n# size of longest rec. annotation\nlast_strides = fmap_size // max_len_annot + 1\n\nmodel.add(keras.layers.Conv1D(filters = 4 , kernel_size= 5 * (2 ** (i+1)), strides=last_strides, padding=\"same\", activation=\"relu\", name=\"conv_output\"))\n\nmodel.compile(loss=\"mse\", metrics=[\"accuracy\"], optimizer=\"sgd\")\n\n\n# conv(tf.expand_dims(parsed_tensor, 0))\n# it = iter(tf.data.TFRecordDataset([fname_tfrecord]).batch(1))\n# serialized = next(it).numpy()\n# parsed_tensor = tf.io.parse_tensor(serialized[0], tf.float32)\n# model.fit(tf.expand_dims(parsed_tensor, 0), target_feature_maps[0][np.newaxis, :, :])\n\ntrain_set = datasetFromTFRecord()\n# model.fit(train_set)\n# model.build(input_shape=[None, max_len, 1])\n# model.summary()\n\nfor e in train_set.batch(1).as_numpy_iterator():\n    model.fit(e[0], e[1])\n#     out = conv(e[0])\n#     print(conv(out))\n\n    \n\n# list(train_set.as_numpy_iterator())\n\n    \n# model.train_on_batch()\n# target_feature_maps[0][np.newaxis, :, :].shape\n\n# model.fit(l_wav_rec, target_feature_maps)\n# model.fit(x2, y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}