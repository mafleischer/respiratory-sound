{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Respiratoy sound automatic annotation (1D Conv, without spectrograms, no downsampling)\nAttempt automatic annotation of sound files in the same format as the provided text files.\nUse the sound data directly without creating spectograms"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport soundfile as sf\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, precision_recall_curve, plot_precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\nimport keras\n\ntry:\n    os.environ['KAGGLE_DATA_PROXY_TOKEN']\nexcept KeyError:\n    dir_out = \"./\"\n    dir_files = \"Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    dir_annot_csv = \"./\"\n    fname_demo = dir_path + \"demographic_info.txt\"\nelse:\n    dir_out = \"/kaggle/working/\"\n    dir_files = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    dir_annot_csv = \"/kaggle/input/recording-annotations/\"\n    fname_demo = \"/kaggle/input/respiratory-sound-database/\" + \"demographic_info.txt\"\n    \nfname_diag = dir_files + \"patient_diagnosis.csv\"\ndir_audio = dir_files + \"audio_and_txt_files/\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"group_pat_num = \"([0-9]{3})\"\ngroup_rec_index = \"([0-9][a-z][0-9])\"\ngroup_chest_loc = \"(Tc|Al|Ar|Pl|Pr|Ll|Lr)\"\ngroup_acc_modes = \"(sc|mc)\"\ngroup_equipments = \"(AKGC417L|LittC2SE|Litt3200|Meditron)\"\n\nregex_info = re.compile(\"_\".join([group_pat_num, group_rec_index, group_chest_loc, group_acc_modes, group_equipments]))\n\ntop = os.getcwd()\nos.chdir(dir_audio)\nfnames = glob.glob(\"*.wav\")\n\nl_wav_rec = []\nmax_len = 0\n\nfor fname in fnames:\n    match_info = regex_info.match(fname)\n    pat_num = int(match_info.group(1))\n    rec_index = match_info.group(2)\n    chest_loc = match_info.group(3)\n    acc_mode = match_info.group(4)\n    equipment = match_info.group(5)\n    \n    wav_content = sf.read(fname)[0]\n    l_wav_rec.append([pat_num, rec_index, chest_loc, wav_content])\n    \n    if len(wav_content) > max_len:\n        max_len = len(wav_content)\n\nos.chdir(top)\n\n# pad all recordings to same length\nfor i in range(len(l_wav_rec)):\n    if len(l_wav_rec[i][3]) < max_len:\n        padding = [0] * ( max_len - len(l_wav_rec[i][3]) )\n        l_wav_rec[i][3] = np.append(l_wav_rec[i][3], padding)\n\nl_wav_rec.sort(key=lambda subl: (subl[0], subl[1], subl[2]))\nwav_cols = [\"Patient number\", \"Recording index\", \"Chest location\", \"WAV\"]\ndf_wav_rec = pd.DataFrame(l_wav_rec, columns=wav_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([[[[1.0,2.0],[1.0,2.0]],[[2.0,3.0],[2.0,3.0]]]])\ny = np.array([[[[2.0,4.0],[2.0,4.0]],[[4.0,6.0],[4.0,6.0]]]])\nx = np.array([[[[1.0]],[[2.0]]]])\ny = np.array([[[[2.0]],[[2.0]]]])\nconv = keras.layers.Conv2D(filters=1,kernel_size=2, strides=1, padding=\"same\", activation=\"relu\")\nmodel = keras.models.Sequential([conv])\nmodel.compile(loss=\"mse\", metrics=[\"accuracy\"], optimizer=\"sgd\")\nmodel.fit(x, y)\nconv.get_weights()[0].shape\nconv.get_weights()[0]\n#x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_annot = pd.read_csv(dir_annot_csv + \"rec_annotation.csv\")\ndf_annot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = np.array([[df_wav_rec.loc[0, \"WAV\"].astype(\"float32\")]])\nx2 = np.array([[df_wav_rec.loc[33, \"WAV\"].astype(\"float32\")]])\ny = np.array([[x for x in range(len(x1[0][0]))]])\n# y = df_annot.loc[0, ]\nconv = keras.layers.Conv1D(filters=1,kernel_size=5, strides=1, padding=\"same\", activation=\"relu\",\n                          input_shape = (None, max_len))\n\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.InputLayer(input_shape=[None, max_len]))\nmodel.add(keras.layers.Conv1D(filters=1,kernel_size=2, strides=1, padding=\"same\", activation=\"relu\",\n                          input_shape = (None, max_len)))\nmodel.add(keras.layers.Conv1D(filters=1,kernel_size=5, strides=1, padding=\"same\", activation=\"relu\",\n                          input_shape = (None, max_len)))\n\nmodel.compile(loss=\"mse\", metrics=[\"accuracy\"], optimizer=\"sgd\")\nmodel.fit(x1, y)\nmodel.fit(x2, y)\n# t = conv(x2)\n# t","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}